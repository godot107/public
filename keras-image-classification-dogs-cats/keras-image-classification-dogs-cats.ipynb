{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc1110c6-d565-48f7-84f0-f87bc040247c",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Practice Convolutional Neural Networks and Image Classification and Image processing\n",
    "\n",
    "## Scenario\n",
    "Given an image of a dog or cat determine\n",
    "\n",
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357cf3f-68ef-4aa1-97f4-da4c2b2d2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc297de0-451f-4ee0-80f6-ecebb64a53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbaf721-1e41-49db-8d34-2d28c1e54c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c49f9-41b6-45b2-9190-3f1b54162d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Images\n",
    "\n",
    "# Source: https://www.kaggle.com/datasets/hassanaitnacer/dogs-vs-cats?select=dogs-vs-cats\n",
    "#f = gzip.open('archive.zip','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2652f-2ffc-40d7-a9a0-6682ec4ac4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open(r\"./dogs-vs-cats/cat/cat.1.jpg\")  \n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a42ed8-2dad-4aab-b2f5-e8d1e9ebb7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify \n",
    "img = Image.open(r\"./dogs-vs-cats/dog/dog.1.jpg\").convert('L')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074c32c-d0ef-4859-a859-a9270c5b38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f39a1-9bc9-4e48-8097-4b233d869b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of converting 2d to a 3d array as part of input channel\n",
    "np.asarray(img).reshape(np.asarray(img).shape[0], np.asarray(img).shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3267b-7112-40c9-9143-5b8b8c42fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create DataFrame\n",
    "df = pd.DataFrame(columns = ['filename','type', 'file_location', 'pixels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e0161-9adf-4a08-9fbe-56681c60a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_images(animal = 'dog'):\n",
    "    global df\n",
    "    for file in glob.glob(f\"./dogs-vs-cats/{animal}/*.jpg\"):\n",
    "        record = []\n",
    "\n",
    "        # len('./dogs-vs-cats/cat/') = 19\n",
    "        record.append(file[19:])\n",
    "        record.append(animal)    \n",
    "        record.append(file)\n",
    "\n",
    "        # Convert Image to greyscale\n",
    "        img = Image.open(file).convert('L')    \n",
    "        \n",
    "        # Resize Image\n",
    "        img =  img.resize((400, 400))\n",
    "        record.append(np.asarray(img).reshape(np.asarray(img).shape[0], np.asarray(img).shape[1],1))\n",
    "\n",
    "        df = pd.concat([df,pd.DataFrame([record], columns =  ['filename','type', 'file_location', 'pixels'])], axis = 0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38a999-e3c6-4e33-9389-20ed561f31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_images('dog')\n",
    "fetch_images('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f4226-92cd-4872-af39-39d4310a1244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)\n",
    "df.drop(columns = ['index'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc7a48-0f13-42f9-8cd0-3a0d9d1c640d",
   "metadata": {},
   "source": [
    "There are 5000 dogs and cats photos. Need to sample and assign to train/test/validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a427f-fa61-47a5-9247-14c3c6228688",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['pixels']\n",
    "X = np.vstack([[X.iloc[i]] for i in range(len(X))])\n",
    "y = df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed4de5-a8fb-4869-81df-cf40ec30e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb854589-3816-4ee3-8d01-9cb38171575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c0f79-a5aa-4422-ad31-e9a95bc0bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca446be1-cfae-4157-b187-cc257416ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the network\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (400,400,1)))\n",
    "\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a34e5c-3adf-406d-b2aa-4540a2c0704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4922ee7-f4aa-4bc4-b1c0-c8f05dff9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "epochs = 5  # for better result increase the epochs\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d2620-1981-4a3c-bc2c-06f9a65621a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # dimesion reduction\n",
    "        rotation_range=5,  # randomly rotate images in the range 5 degrees\n",
    "        zoom_range = 0.1, # Randomly zoom image 10%\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally 10%\n",
    "        height_shift_range=0.1,  # randomly shift images vertically 10%\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083371f5-7478-4e56-b22f-bdb01881ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2942920-72c5-4c3a-9b99-afc84da326f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the Model\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val, y_val))#, steps_per_epoch=X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f89481-18fe-422a-a268-9042118a7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "plt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e87d28-bdb6-4c3a-acce-a41e097c8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Predictions\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964cffb-5f7f-46cb-a26b-4aa551eef451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate \n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "\n",
    "# Convert validation observations to one hot vectors\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a70ab-94f3-4adf-8c51-b63c05dcf83b",
   "metadata": {},
   "source": [
    "Looking Ahead\n",
    "Pull images using gunzip and archive.zip\n",
    "Create CNN with all 3 channels.\n",
    "Research/Resources/References\n",
    "https://www.kaggle.com/datasets/hassanaitnacer/dogs-vs-cats?select=dogs-vs-cats\n",
    "https://stackoverflow.com/questions/1109422/getting-list-of-pixel-values-from-pil\n",
    "https://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python\n",
    "converting each image to greyscale\n",
    "https://www.w3schools.com/python/python_variables_global.asp\n",
    "for creation function fetch_images\n",
    "https://imagekit.io/blog/image-resizing-in-python/\n",
    "resizing images\n",
    "https://www.atmosera.com/blog/binary-classification-with-neural-networks/\n",
    "binary classification for image\n",
    "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
    "binary labeler\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
