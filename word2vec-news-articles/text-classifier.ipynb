{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81861cd-6aab-4b54-9ba2-af98c2772c4b",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Use word embeddings to train a classifier\n",
    "\n",
    "## Goal\n",
    "- Based on content of an article, predict its newstype using logistic regression\n",
    "\n",
    "## Intuition\n",
    "Doc2Vec is an extension of word2vec. It helps get context from overall document. \n",
    "\n",
    "## Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9332e314-722f-4fcf-84ed-c6b3ecf775b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8865ee26-2508-4006-8928-f7b9a902dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76654934-2bd7-46ec-a325-9d3ca256834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "#Source: https://www.kaggle.com/datasets/asad1m9a9h6mood/news-articles?select=Articles.csv\n",
    "df = pd.read_csv('./data/Articles.csv', encoding=\"ISO-8859-1\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c80e49f-a227-417a-b61c-7ec31db56d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Pre-process\n",
    "\n",
    "# tokenize while removing stop words because they hold no value\n",
    "def token_helper(doc):\n",
    "    global stops\n",
    "    payload = [word.lower() for word in word_tokenize(doc) if word not in stops and word.isalpha()]    \n",
    "    return payload\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "# Drop empty rows\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "# Encode Target\n",
    "df['NewsType'] = df['NewsType'].replace({'business':0, 'sports':1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5507e559-f869-40bc-bda9-d486a2e7c2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nltk_tokensized_bios[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c780310d-dbfb-4ec8-b6bb-23d78ebed354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article      Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  1/1/2015   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  1/2/2015   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  1/5/2015   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo...  1/6/2015   \n",
       "4  NEW YORK: US oil prices Monday slipped below $...  1/6/2015   \n",
       "\n",
       "                                             Heading  NewsType  \n",
       "0  sindh govt decides to cut public transport far...         0  \n",
       "1                    asia stocks up in new year trad         0  \n",
       "2           hong kong stocks open 0.66 percent lower         0  \n",
       "3             asian stocks sink euro near nine year          0  \n",
       "4                 us oil prices slip below 50 a barr         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f743a609-92d2-4cc6-96d6-78495300f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Article'], df['NewsType'] , test_size = .2, random_state = seed)\n",
    "\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(df['Article'], df['NewsType'] , test_size = .2, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2a1b10c-3fb4-418f-8bdf-50e74c94e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Baseline Model\n",
    "vectorizer =  TfidfVectorizer(min_df = 500, stop_words = 'english')\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f4d856-3b62-44bc-b5e0-fb5f90644924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(random_state = seed)\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc32cfa-7b5c-42f8-9360-804ebe0a7ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84469bb34e574672b9c6802ca2f70d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Word2Vec Approach\n",
    "nltk_tokensized_bios = [token_helper(doc) for doc in tqdm(X_train_w2v.values)]\n",
    "w2v_model = Word2Vec(nltk_tokensized_bios, vector_size=100, window=5, min_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6875ea0-1987-4677-8a64-08fd1910b4ce",
   "metadata": {},
   "source": [
    "After training the Word2Vec model, you can represent each article as a vector by taking the average of the Word2Vec embeddings of the words in the article. This makes a vector representation of the article that shows how the words fit together and what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c165bfd1-199d-4bbf-8c65-f7f270703113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/\n",
    "\n",
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.ze ros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7742671c-5612-4d9a-a1bb-176488c0c6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v = np.array([vectorize(sentence) for sentence in X_train_w2v])\n",
    "X_test_w2v = np.array([vectorize(sentence) for sentence in X_test_w2v])\n",
    "\n",
    "w2v_lr_clf = LogisticRegression(random_state = seed)\n",
    "w2v_lr_clf.fit(X_train_w2v, y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0600963b-7554-4194-8e91-fd9f40578c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Predictions\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "w2v_lr_pred = w2v_lr_clf.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c28fec9-5443-478c-9bad-63bafd124171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate Model\n",
    "\n",
    "lr_f1 = f1_score(y_test, lr_pred, average='macro')\n",
    "w2v_lr_f1 = f1_score(y_test_w2v, w2v_lr_pred , average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1328d715-ecf3-47b9-8202-3b175dd20bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8886731658955718\n",
      "0.9721518987341772\n"
     ]
    }
   ],
   "source": [
    "print(lr_f1)\n",
    "print(w2v_lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8e936-eb2c-45dc-8d38-1f140fd982f7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "## Looking ahead:\n",
    "- use a pre-trained embedding as opposed to making my own. \n",
    "- consider using neural network\n",
    "\n",
    "## Research/References:\n",
    "- https://towardsdatascience.com/text-classification-using-word-embeddings-and-deep-learning-in-python-classifying-tweets-from-6fe644fcfc81\n",
    "- https://www.kaggle.com/code/kstathou/word-embeddings-logistic-regression\n",
    "  - for baseline model\n",
    "- https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "- https://stats.stackexchange.com/questions/299446/word-embeddings-with-logistic-regression\n",
    "- https://www.kaggle.com/datasets/asad1m9a9h6mood/news-articles?select=Articles.csv\n",
    "  - Data Source\n",
    "- https://medium.com/@dilip.voleti/classification-using-word2vec-b1d79d375381\n",
    "  - for word2vec classification\n",
    "- https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794\n",
    "  - deep learning reference\n",
    "- https://thinkingneuron.com/how-to-classify-text-using-word2vec/\n",
    "- https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/\n",
    "- early stopping:\n",
    "    - https://pythonguides.com/pytorch-early-stopping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffba1d1-31ea-408f-98e6-fe747aced9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
